\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrt}
\citation{yeh}
\citation{UCI}
\citation{yeh}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{project2}
\citation{Geron}
\citation{Geron}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Decision Trees}{2}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Iris Decision Tree\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figT:iris_tree}{{2.1}{3}{Iris Decision Tree\relax }{figure.caption.1}{}}
\newlabel{eqT:gini_score}{{1}{4}{Decision Trees}{equation.2.1}{}}
\newlabel{eqT:CART_cost}{{2}{4}{Decision Trees}{equation.2.2}{}}
\newlabel{eqT:entropy_cost}{{3}{4}{Decision Trees}{equation.2.3}{}}
\citation{Geron}
\citation{Geron}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Random Forests}{5}{subsection.2.2}}
\citation{yeh}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gain curves}{6}{subsection.2.3}}
\citation{github}
\citation{UCI}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental}{7}{section.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The different input arguments and their effect when running \texttt  {src/main.py}\relax }}{7}{table.caption.2}}
\newlabel{tabE:sysargv}{{1}{7}{The different input arguments and their effect when running \texttt {src/main.py}\relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{8}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Logistic Regression}{8}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Accuracy as a function of $\lambda $ value for our Logistic Regression model\relax }}{8}{figure.caption.3}}
\newlabel{figR:LogRegParam}{{4.1}{8}{Accuracy as a function of $\lambda $ value for our Logistic Regression model\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Gain chart for our Logistic Regression\relax }}{9}{figure.caption.4}}
\newlabel{figR:LogReggain}{{4.2}{9}{Gain chart for our Logistic Regression\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Neural Network}{9}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A comparison of the Neural Net accuracy between the parameters Momentum and Decay.\relax }}{10}{figure.caption.5}}
\newlabel{figR:cpMomDec}{{4.3}{10}{A comparison of the Neural Net accuracy between the parameters Momentum and Decay.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A comparison of the Neural Net accuracy between the parameters Epoch and Batch size.\relax }}{10}{figure.caption.6}}
\newlabel{figR:cpEpBS}{{4.4}{10}{A comparison of the Neural Net accuracy between the parameters Epoch and Batch size.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A comparison of the Neural Net accuracy between the parameters $\lambda $ and learning rate.\relax }}{11}{figure.caption.7}}
\newlabel{figR:cplmblr}{{4.5}{11}{A comparison of the Neural Net accuracy between the parameters $\lambda $ and learning rate.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces A comparison of the Neural Net accuracy between the parameters epoch and learning rate.\relax }}{11}{figure.caption.8}}
\newlabel{figR:cpEplr}{{4.6}{11}{A comparison of the Neural Net accuracy between the parameters epoch and learning rate.\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameters chosen for our neural network\relax }}{12}{table.caption.9}}
\newlabel{tabR:parameters}{{2}{12}{Parameters chosen for our neural network\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Gain chart for our Neural Network\relax }}{12}{figure.caption.10}}
\newlabel{figR:nngain}{{4.7}{12}{Gain chart for our Neural Network\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Random Forrest}{13}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces A comparison of the Random Forrest accuracy between the parameters\relax }}{13}{figure.caption.11}}
\newlabel{figR:randomforrest1}{{4.8}{13}{A comparison of the Random Forrest accuracy between the parameters\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces A comparison of the Random Forrest accuracy between the parameters\relax }}{13}{figure.caption.12}}
\newlabel{figR:randomforrest2}{{4.9}{13}{A comparison of the Random Forrest accuracy between the parameters\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces A comparison of the Random Forrest accuracy between the parameters\relax }}{14}{figure.caption.13}}
\newlabel{figR:randomforrest3}{{4.10}{14}{A comparison of the Random Forrest accuracy between the parameters\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces A comparison of the Random Forrest accuracy between the parameters\relax }}{14}{figure.caption.14}}
\newlabel{figR:randomforrest4}{{4.11}{14}{A comparison of the Random Forrest accuracy between the parameters\relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Estimated optimal parameters for our Random Forrest model\relax }}{15}{table.caption.15}}
\newlabel{tabR:RFparameters}{{3}{15}{Estimated optimal parameters for our Random Forrest model\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Estimated optimal parameters through trial and error for our Random Forrest model\relax }}{15}{table.caption.16}}
\newlabel{tabR:RFparameters2}{{4}{15}{Estimated optimal parameters through trial and error for our Random Forrest model\relax }{table.caption.16}{}}
\citation{yeh}
\citation{yeh}
\citation{Geron}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Gain chart for our Random Forrest with guessed parameters\relax }}{16}{figure.caption.17}}
\newlabel{figR:randomforrest}{{4.12}{16}{Gain chart for our Random Forrest with guessed parameters\relax }{figure.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Area ratio between area of gain curve divided by area of optimal curve. Both areas are measured from above the baseline.\relax }}{16}{table.caption.18}}
\newlabel{tabR:arearatio}{{5}{16}{Area ratio between area of gain curve divided by area of optimal curve. Both areas are measured from above the baseline.\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{16}{section.5}}
\citation{yeh}
\bibdata{lib}
\bibcite{UCI}{1}
\bibcite{yeh}{2}
\bibcite{project2}{3}
\bibcite{Geron}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Future works}{19}{subsection.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{19}{section.6}}
